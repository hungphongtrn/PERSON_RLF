uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-5 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=1e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=identity dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=true loss.softlabel_ratio=0.5
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0
uv run trainer.py  -cn tbps_clip backbone=siglip tokenizer=siglip dataset.batch_size=8 trainer.accumulate_grad_batches=8 optimizer.type=bitsandbytes.optim.AdamW8bit dataset.dataset_name=VN3K_VI loss.RITC=false optimizer.lr=3e-4 dataset.sampler=random dataset.num_instance=1 backbone.use_sigmoid=false loss.softlabel_ratio=0.5